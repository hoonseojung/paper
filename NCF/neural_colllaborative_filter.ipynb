{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/sslab/anaconda3/bin/python'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "weight_dir = '/media/sslab/1390f618-020d-402b-871b-0238fac8293c/Atomy/hoonseo/ncf_weight/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>3.0</td>\n",
       "      <td>964982400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964980868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964984041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964984100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931\n",
       "5       1       70     3.0  964982400\n",
       "6       1      101     5.0  964980868\n",
       "7       1      110     4.0  964982176\n",
       "8       1      151     5.0  964984041\n",
       "9       1      157     5.0  964984100"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df = pd.read_csv('ratings.csv')\n",
    "ratings_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 User 수: 610\n",
      "전체 Item 수: 9724\n",
      "행렬의 희소성: 0.9830\n"
     ]
    }
   ],
   "source": [
    "num_user = ratings_df['userId'].nunique()\n",
    "num_item = ratings_df['movieId'].nunique()\n",
    "\n",
    "sparsity = 1 - len(ratings_df) / (num_user * num_item)\n",
    "\n",
    "print(f'전체 User 수: {num_user}')\n",
    "print(f'전체 Item 수: {num_item}')\n",
    "print(f'행렬의 희소성: {sparsity:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Rating distribution')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.histplot(ratings_df['rating'])\n",
    "plt.title('Rating distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_encoder, user_decoder = {}, {}\n",
    "for idx, user_id in enumerate(ratings_df['userId'].unique()):\n",
    "    user_encoder[user_id] = idx\n",
    "    user_decoder[idx] = user_id\n",
    "\n",
    "item_encoder, item_decoder = {}, {}\n",
    "for idx, item_id in enumerate(ratings_df['movieId'].unique()):\n",
    "    item_encoder[item_id] = idx\n",
    "    item_decoder[idx] = item_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df['en_userId'] = ratings_df['userId'].apply(lambda x : user_encoder[x])\n",
    "ratings_df['en_movieId'] = ratings_df['movieId'].apply(lambda x : item_encoder[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df, num_neg = 3):\n",
    "    # positive 1개당 negative sampling 3개\n",
    "    total_item_li = set([i for i in range(num_item)])\n",
    "    train_df = []\n",
    "    test_df = []\n",
    "    en_user_id_li = df['en_userId'].unique()\n",
    "    for en_user_id in tqdm(en_user_id_li):\n",
    "        pos_recomencder_li = df[df['en_userId'] == en_user_id]['en_movieId'].tolist()\n",
    "        neg_recomencder_li = np.random.choice(list(total_item_li - set(pos_recomencder_li)), num_neg * len(pos_recomencder_li), replace = False).tolist()\n",
    "        train_df += [[en_user_id, en_movieId, 1] for en_movieId in pos_recomencder_li[:-1]] + [[en_user_id, en_movieId, 0] for en_movieId in neg_recomencder_li]\n",
    "\n",
    "        neg_recomencder_li = np.random.choice(list(total_item_li - set(pos_recomencder_li)), 99, replace = False).tolist()\n",
    "        test_df += [[en_user_id, pos_recomencder_li[-1], 1]] + [[en_user_id, en_movieId, 0] for en_movieId in neg_recomencder_li]\n",
    "    \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        user = self.df[idx][0]\n",
    "        item = self.df[idx][1]\n",
    "        label = self.df[idx][2]\n",
    "\n",
    "        return user, item, label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GMF(Generalized Matrix Factorization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMF(nn.Module):\n",
    "    def __init__(self, num_user, num_item, num_factor):\n",
    "        super(GMF, self).__init__()\n",
    "        self.user_emb = nn.Embedding(num_user, num_factor)\n",
    "        self.item_emb = nn.Embedding(num_item, num_factor)\n",
    "        \n",
    "        self.predict_layer = nn.Sequential(\n",
    "            nn.Linear(num_factor, 1, bias = False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self._init_weight_()\n",
    "    \n",
    "    def _init_weight_(self):\n",
    "        nn.init.normal_(self.user_emb.weight, std=0.01)\n",
    "        nn.init.normal_(self.item_emb.weight, std=0.01)\n",
    "        for m in self.predict_layer:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_uniform_(m.weight, a=1, nonlinearity=\"sigmoid\")\n",
    "                # kaiming 초기화 : 정규 분포를 사용해 가중치를 초기화\n",
    "    \n",
    "    def forward(self, user, item):\n",
    "        user_emb = self.user_emb(user)\n",
    "        item_emb = self.item_emb(item)\n",
    "\n",
    "        output = self.predict_layer(user_emb * item_emb) # element-wise product\n",
    "\n",
    "        return output.view(-1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP(Multi Layer Perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, num_user, num_item, num_factor, num_layers, dropout):\n",
    "        super(MLP, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        self.user_emb = nn.Embedding(num_user, num_factor)\n",
    "        self.item_emb = nn.Embedding(num_item, num_factor)\n",
    "\n",
    "        MLP_modules = []\n",
    "        input_size = num_factor * 2\n",
    "        for _ in range(num_layers):\n",
    "            MLP_modules.append(nn.Dropout(p = self.dropout))\n",
    "            MLP_modules.append(nn.Linear(input_size, input_size // 2))\n",
    "            MLP_modules.append(nn.ReLU())\n",
    "            input_size = input_size // 2\n",
    "        self.MLP_layers = nn.Sequential(*MLP_modules)\n",
    "\n",
    "        self.predict_layer = nn.Sequential(\n",
    "            nn.Linear(input_size, 1, bias = False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self._init_weight_()\n",
    "    \n",
    "    def _init_weight_(self):\n",
    "        nn.init.normal_(self.user_emb.weight, std=0.01)\n",
    "        nn.init.normal_(self.item_emb.weight, std=0.01)\n",
    "        for m in self.MLP_layers:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                # xavier 초기화 : hidden layer의 노드 수에 따라 다른 표준 편차를 할당하여 가중치 초기화\n",
    "        \n",
    "        for m in self.predict_layer:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_uniform_(m.weight, a=1, nonlinearity=\"sigmoid\")\n",
    "    \n",
    "    def forward(self, user, item):\n",
    "        user_emb = self.user_emb(user)\n",
    "        item_emb = self.item_emb(item)\n",
    "        \n",
    "        cat_emb = torch.cat((user_emb, item_emb), -1) # concat\n",
    "\n",
    "        output = self.MLP_layers(cat_emb)\n",
    "\n",
    "        output = self.predict_layer(output)\n",
    "\n",
    "        return output.view(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NeuMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuMF(nn.Module):\n",
    "    def __init__(self, GMF, MLP, num_factor):\n",
    "        super(NeuMF, self).__init__()\n",
    "        # GMF와 MLP 서로 다른 embedding layer\n",
    "        self.gmf_user_emb = GMF.user_emb\n",
    "        self.gmf_item_emb = GMF.item_emb\n",
    "\n",
    "        self.mlp_user_emb = MLP.user_emb\n",
    "        self.mlp_item_emb = MLP.item_emb\n",
    "\n",
    "        self.mlp_layer = MLP.MLP_layers # 마지막 predict layer\n",
    "\n",
    "        self.predict_layer = nn.Sequential(\n",
    "            nn.Linear(num_factor + (num_factor // 2), 1, bias = False),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        self._init_weight_()\n",
    "    \n",
    "    def _init_weight_(self):\n",
    "        for m in self.predict_layer:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_uniform_(m.weight, a=1, nonlinearity=\"sigmoid\")\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        gmf_user_emb = self.gmf_user_emb(user)\n",
    "        gmf_item_emb = self.gmf_item_emb(item)\n",
    "        gmf_output = gmf_user_emb * gmf_item_emb # element-wise product\n",
    "\n",
    "        mlp_user_emb = self.mlp_user_emb(user)\n",
    "        mlp_item_emb = self.mlp_item_emb(item)\n",
    "        mlp_cat_emb = torch.cat((mlp_user_emb, mlp_item_emb), -1) # concat\n",
    "        mlp_output = self.mlp_layer(mlp_cat_emb)\n",
    "        \n",
    "        cat_output = torch.cat((gmf_output, mlp_output), -1) # concat\n",
    "\n",
    "        output = self.predict_layer(cat_output)\n",
    "\n",
    "        return output.view(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit(target_item, pred_items):\n",
    "    if target_item in pred_items:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def ndcg(target_item, pred_items):\n",
    "    if target_item in pred_items:\n",
    "        idx = pred_items.index(target_item)\n",
    "        # 초기 인덱스가 0이기 때문에 +2 함\n",
    "        return np.reciprocal(np.log2(idx + 2))\n",
    "    return 0\n",
    "\n",
    "def metrics(model, test_loader, top_k):\n",
    "    model.eval()\n",
    "    HR, NDCG = [], []\n",
    "    with torch.no_grad():\n",
    "        for user, item, _ in test_loader:\n",
    "            user = user.to(device)\n",
    "            item = item.to(device)\n",
    "\n",
    "            predictions = model(user, item)\n",
    "            # 가장 높은 top_k개 선택\n",
    "            _, indices = torch.topk(predictions, top_k)\n",
    "            # 해당 상품 index 선택\n",
    "            recommends = torch.take(item, indices).cpu().numpy().tolist()\n",
    "            # 정답값 선택\n",
    "            target_item = item[0].item()\n",
    "            HR.append(hit(target_item, recommends))\n",
    "            NDCG.append(ndcg(target_item, recommends))\n",
    "\n",
    "    return np.mean(HR), np.mean(NDCG)\n",
    "    \n",
    "def train(model, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    for user, item, label in train_loader:\n",
    "        user = user.to(device)\n",
    "        item = item.to(device)\n",
    "        label = label.to(device)\n",
    "        label = label.float()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(user, item)\n",
    "        loss = criterion(output, label)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "batch_size = 256\n",
    "epochs = 30\n",
    "lr = 0.005\n",
    "num_factor = 64\n",
    "num_layers = 2\n",
    "dropout = 0.2\n",
    "top_k = 30\n",
    "num_neg = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 610/610 [00:01<00:00, 364.29it/s]\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = split_data(df = ratings_df, num_neg = num_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(301898, 61000)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(df = train_df)\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True, drop_last = False)\n",
    "\n",
    "test_dataset = CustomDataset(df = test_df)\n",
    "test_loader = DataLoader(test_dataset, batch_size = 100, shuffle = False, drop_last = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GMF + MLP pre-train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmf = GMF(num_user = num_user, num_item = num_item, num_factor = num_factor).to(device)\n",
    "gmf_optimizer = torch.optim.Adam(gmf.parameters(), lr = lr)\n",
    "\n",
    "mlp = MLP(num_user = num_user, num_item = num_item, num_factor = num_factor, num_layers = num_layers, dropout = dropout).to(device)\n",
    "mlp_optimizer = torch.optim.Adam(mlp.parameters(), lr = lr)\n",
    "\n",
    "loss_fc = nn.BCELoss() # Binary Cross Entropy Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH: 1], GMF Train Loss: 0.4661, MLP Train Loss: 0.4408, GMF HR: 0.7590, MLP HR: 0.7262, GMF NDCG: 0.3468, MLP NDCG: 0.3355\n",
      "[EPOCH: 2], GMF Train Loss: 0.2598, MLP Train Loss: 0.3997, GMF HR: 0.7738, MLP HR: 0.7328, GMF NDCG: 0.3444, MLP NDCG: 0.3346\n",
      "[EPOCH: 3], GMF Train Loss: 0.0774, MLP Train Loss: 0.3873, GMF HR: 0.7525, MLP HR: 0.7361, GMF NDCG: 0.3328, MLP NDCG: 0.3400\n",
      "[EPOCH: 4], GMF Train Loss: 0.0190, MLP Train Loss: 0.3691, GMF HR: 0.7525, MLP HR: 0.7410, GMF NDCG: 0.3393, MLP NDCG: 0.3453\n",
      "[EPOCH: 5], GMF Train Loss: 0.0046, MLP Train Loss: 0.3434, GMF HR: 0.7557, MLP HR: 0.7492, GMF NDCG: 0.3438, MLP NDCG: 0.3642\n",
      "[EPOCH: 6], GMF Train Loss: 0.0012, MLP Train Loss: 0.3180, GMF HR: 0.7623, MLP HR: 0.7426, GMF NDCG: 0.3467, MLP NDCG: 0.3511\n",
      "[EPOCH: 7], GMF Train Loss: 0.0003, MLP Train Loss: 0.2996, GMF HR: 0.7557, MLP HR: 0.7574, GMF NDCG: 0.3496, MLP NDCG: 0.3541\n",
      "[EPOCH: 8], GMF Train Loss: 0.0001, MLP Train Loss: 0.2870, GMF HR: 0.7574, MLP HR: 0.7475, GMF NDCG: 0.3495, MLP NDCG: 0.3625\n",
      "[EPOCH: 9], GMF Train Loss: 0.0001, MLP Train Loss: 0.2761, GMF HR: 0.7574, MLP HR: 0.7607, GMF NDCG: 0.3515, MLP NDCG: 0.3580\n",
      "[EPOCH: 10], GMF Train Loss: 0.0000, MLP Train Loss: 0.2686, GMF HR: 0.7574, MLP HR: 0.7541, GMF NDCG: 0.3526, MLP NDCG: 0.3589\n",
      "[EPOCH: 11], GMF Train Loss: 0.0000, MLP Train Loss: 0.2604, GMF HR: 0.7590, MLP HR: 0.7475, GMF NDCG: 0.3560, MLP NDCG: 0.3588\n",
      "[EPOCH: 12], GMF Train Loss: 0.0000, MLP Train Loss: 0.2541, GMF HR: 0.7590, MLP HR: 0.7508, GMF NDCG: 0.3601, MLP NDCG: 0.3590\n",
      "[EPOCH: 13], GMF Train Loss: 0.0000, MLP Train Loss: 0.2485, GMF HR: 0.7574, MLP HR: 0.7541, GMF NDCG: 0.3612, MLP NDCG: 0.3638\n",
      "[EPOCH: 14], GMF Train Loss: 0.0000, MLP Train Loss: 0.2430, GMF HR: 0.7557, MLP HR: 0.7541, GMF NDCG: 0.3629, MLP NDCG: 0.3589\n",
      "[EPOCH: 15], GMF Train Loss: 0.0000, MLP Train Loss: 0.2387, GMF HR: 0.7574, MLP HR: 0.7656, GMF NDCG: 0.3674, MLP NDCG: 0.3608\n",
      "[EPOCH: 16], GMF Train Loss: 0.0000, MLP Train Loss: 0.2343, GMF HR: 0.7557, MLP HR: 0.7459, GMF NDCG: 0.3683, MLP NDCG: 0.3555\n",
      "[EPOCH: 17], GMF Train Loss: 0.0000, MLP Train Loss: 0.2305, GMF HR: 0.7574, MLP HR: 0.7590, GMF NDCG: 0.3726, MLP NDCG: 0.3525\n",
      "[EPOCH: 18], GMF Train Loss: 0.0000, MLP Train Loss: 0.2269, GMF HR: 0.7590, MLP HR: 0.7607, GMF NDCG: 0.3762, MLP NDCG: 0.3617\n",
      "[EPOCH: 19], GMF Train Loss: 0.0000, MLP Train Loss: 0.2238, GMF HR: 0.7590, MLP HR: 0.7672, GMF NDCG: 0.3763, MLP NDCG: 0.3699\n",
      "[EPOCH: 20], GMF Train Loss: 0.0000, MLP Train Loss: 0.2199, GMF HR: 0.7607, MLP HR: 0.7607, GMF NDCG: 0.3719, MLP NDCG: 0.3663\n",
      "[EPOCH: 21], GMF Train Loss: 0.0000, MLP Train Loss: 0.2170, GMF HR: 0.7590, MLP HR: 0.7672, GMF NDCG: 0.3726, MLP NDCG: 0.3625\n",
      "[EPOCH: 22], GMF Train Loss: 0.0000, MLP Train Loss: 0.2145, GMF HR: 0.7590, MLP HR: 0.7672, GMF NDCG: 0.3711, MLP NDCG: 0.3566\n",
      "[EPOCH: 23], GMF Train Loss: 0.0000, MLP Train Loss: 0.2108, GMF HR: 0.7590, MLP HR: 0.7557, GMF NDCG: 0.3724, MLP NDCG: 0.3581\n",
      "[EPOCH: 24], GMF Train Loss: 0.0000, MLP Train Loss: 0.2092, GMF HR: 0.7590, MLP HR: 0.7639, GMF NDCG: 0.3702, MLP NDCG: 0.3711\n",
      "[EPOCH: 25], GMF Train Loss: 0.0000, MLP Train Loss: 0.2081, GMF HR: 0.7607, MLP HR: 0.7541, GMF NDCG: 0.3705, MLP NDCG: 0.3571\n",
      "[EPOCH: 26], GMF Train Loss: 0.0000, MLP Train Loss: 0.2054, GMF HR: 0.7607, MLP HR: 0.7672, GMF NDCG: 0.3759, MLP NDCG: 0.3569\n",
      "[EPOCH: 27], GMF Train Loss: 0.0000, MLP Train Loss: 0.2033, GMF HR: 0.7590, MLP HR: 0.7541, GMF NDCG: 0.3744, MLP NDCG: 0.3782\n",
      "[EPOCH: 28], GMF Train Loss: 0.0000, MLP Train Loss: 0.2009, GMF HR: 0.7590, MLP HR: 0.7672, GMF NDCG: 0.3778, MLP NDCG: 0.3716\n",
      "[EPOCH: 29], GMF Train Loss: 0.0000, MLP Train Loss: 0.1987, GMF HR: 0.7574, MLP HR: 0.7689, GMF NDCG: 0.3792, MLP NDCG: 0.3772\n",
      "[EPOCH: 30], GMF Train Loss: 0.0000, MLP Train Loss: 0.1962, GMF HR: 0.7557, MLP HR: 0.7721, GMF NDCG: 0.3772, MLP NDCG: 0.3628\n"
     ]
    }
   ],
   "source": [
    "gmf_best_metric = 0\n",
    "mlp_best_metric = 0\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    gmf_train_loss = train(model = gmf, train_loader = train_loader, criterion = loss_fc, optimizer = gmf_optimizer)\n",
    "    gmf_hr, gmf_ndcg = metrics(model = gmf, test_loader = test_loader, top_k = top_k)\n",
    "\n",
    "    mlp_train_loss = train(model = mlp, train_loader = train_loader, criterion = loss_fc, optimizer = mlp_optimizer)\n",
    "    mlp_hr, mlp_ndcg  = metrics(model = mlp, test_loader = test_loader, top_k = top_k)\n",
    "\n",
    "    print(f\"[EPOCH: {epoch}], GMF Train Loss: {gmf_train_loss:.4f}, MLP Train Loss: {mlp_train_loss:.4f}, GMF HR: {gmf_hr:.4f}, MLP HR: {mlp_hr:.4f}, GMF NDCG: {gmf_ndcg:.4f}, MLP NDCG: {mlp_ndcg:.4f}\")\n",
    "\n",
    "    if gmf_best_metric < gmf_ndcg:\n",
    "        gmf_best_metric = gmf_ndcg\n",
    "        torch.save(gmf.state_dict(), weight_dir + f'GMF.pt')\n",
    "\n",
    "    if mlp_best_metric < mlp_ndcg:\n",
    "        mlp_best_metric = mlp_ndcg\n",
    "        torch.save(mlp.state_dict(), weight_dir + f'MLP.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NeuMF train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NeuMF 의 경우 pre-trained 모델을 사용한다고 함\n",
    "# 그리고 optimizer로 SGD를 사용한다고 함\n",
    "# 실제로 Adam 보다 더 좋은 성능을 보임\n",
    "\n",
    "gmf = GMF(num_user = num_user, num_item = num_item, num_factor = num_factor).to(device)\n",
    "gmf.load_state_dict(torch.load(weight_dir + f'GMF.pt'))\n",
    "\n",
    "mlp = MLP(num_user = num_user, num_item = num_item, num_factor = num_factor, num_layers = num_layers, dropout = dropout).to(device)\n",
    "mlp.load_state_dict(torch.load(weight_dir + f'MLP.pt'))\n",
    "\n",
    "nmf = NeuMF(GMF = gmf, MLP = mlp, num_factor = num_factor).to(device)\n",
    "nmf_optimizer = torch.optim.SGD(nmf.parameters(), lr = lr, momentum = 0.9) # SGD 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH: 1], NeuMF Train Loss: 0.1268, NeuMF HR: 0.7639, NeuMF NDCG: 0.3875\n",
      "[EPOCH: 2], NeuMF Train Loss: 0.0594, NeuMF HR: 0.7770, NeuMF NDCG: 0.3848\n",
      "[EPOCH: 3], NeuMF Train Loss: 0.0381, NeuMF HR: 0.7738, NeuMF NDCG: 0.3828\n",
      "[EPOCH: 4], NeuMF Train Loss: 0.0278, NeuMF HR: 0.7787, NeuMF NDCG: 0.3811\n",
      "[EPOCH: 5], NeuMF Train Loss: 0.0218, NeuMF HR: 0.7705, NeuMF NDCG: 0.3757\n",
      "[EPOCH: 6], NeuMF Train Loss: 0.0178, NeuMF HR: 0.7738, NeuMF NDCG: 0.3741\n",
      "[EPOCH: 7], NeuMF Train Loss: 0.0152, NeuMF HR: 0.7721, NeuMF NDCG: 0.3725\n",
      "[EPOCH: 8], NeuMF Train Loss: 0.0131, NeuMF HR: 0.7738, NeuMF NDCG: 0.3730\n",
      "[EPOCH: 9], NeuMF Train Loss: 0.0116, NeuMF HR: 0.7689, NeuMF NDCG: 0.3740\n",
      "[EPOCH: 10], NeuMF Train Loss: 0.0103, NeuMF HR: 0.7705, NeuMF NDCG: 0.3722\n",
      "[EPOCH: 11], NeuMF Train Loss: 0.0093, NeuMF HR: 0.7721, NeuMF NDCG: 0.3724\n",
      "[EPOCH: 12], NeuMF Train Loss: 0.0085, NeuMF HR: 0.7705, NeuMF NDCG: 0.3719\n",
      "[EPOCH: 13], NeuMF Train Loss: 0.0078, NeuMF HR: 0.7689, NeuMF NDCG: 0.3729\n",
      "[EPOCH: 14], NeuMF Train Loss: 0.0073, NeuMF HR: 0.7689, NeuMF NDCG: 0.3720\n",
      "[EPOCH: 15], NeuMF Train Loss: 0.0068, NeuMF HR: 0.7754, NeuMF NDCG: 0.3731\n",
      "[EPOCH: 16], NeuMF Train Loss: 0.0063, NeuMF HR: 0.7705, NeuMF NDCG: 0.3722\n",
      "[EPOCH: 17], NeuMF Train Loss: 0.0059, NeuMF HR: 0.7738, NeuMF NDCG: 0.3710\n",
      "[EPOCH: 18], NeuMF Train Loss: 0.0056, NeuMF HR: 0.7721, NeuMF NDCG: 0.3724\n",
      "[EPOCH: 19], NeuMF Train Loss: 0.0053, NeuMF HR: 0.7721, NeuMF NDCG: 0.3723\n",
      "[EPOCH: 20], NeuMF Train Loss: 0.0050, NeuMF HR: 0.7721, NeuMF NDCG: 0.3722\n",
      "[EPOCH: 21], NeuMF Train Loss: 0.0048, NeuMF HR: 0.7721, NeuMF NDCG: 0.3715\n",
      "[EPOCH: 22], NeuMF Train Loss: 0.0045, NeuMF HR: 0.7705, NeuMF NDCG: 0.3714\n",
      "[EPOCH: 23], NeuMF Train Loss: 0.0043, NeuMF HR: 0.7689, NeuMF NDCG: 0.3701\n",
      "[EPOCH: 24], NeuMF Train Loss: 0.0041, NeuMF HR: 0.7705, NeuMF NDCG: 0.3720\n",
      "[EPOCH: 25], NeuMF Train Loss: 0.0039, NeuMF HR: 0.7705, NeuMF NDCG: 0.3713\n",
      "[EPOCH: 26], NeuMF Train Loss: 0.0038, NeuMF HR: 0.7705, NeuMF NDCG: 0.3708\n",
      "[EPOCH: 27], NeuMF Train Loss: 0.0036, NeuMF HR: 0.7721, NeuMF NDCG: 0.3698\n",
      "[EPOCH: 28], NeuMF Train Loss: 0.0035, NeuMF HR: 0.7705, NeuMF NDCG: 0.3713\n",
      "[EPOCH: 29], NeuMF Train Loss: 0.0034, NeuMF HR: 0.7705, NeuMF NDCG: 0.3705\n",
      "[EPOCH: 30], NeuMF Train Loss: 0.0033, NeuMF HR: 0.7705, NeuMF NDCG: 0.3698\n"
     ]
    }
   ],
   "source": [
    "nmf_best_metric = 0\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    nmf_train_loss = train(model = nmf, train_loader = train_loader, criterion = loss_fc, optimizer = nmf_optimizer)\n",
    "    nmf_hr, nmf_ndcg = metrics(model = nmf, test_loader = test_loader, top_k = top_k)\n",
    "\n",
    "    print(f\"[EPOCH: {epoch}], NeuMF Train Loss: {nmf_train_loss:.4f}, NeuMF HR: {nmf_hr:.4f}, NeuMF NDCG: {nmf_ndcg:.4f}\")\n",
    "\n",
    "    if nmf_best_metric < nmf_ndcg:\n",
    "        nmf_best_metric = nmf_ndcg\n",
    "        torch.save(nmf.state_dict(), weight_dir + f'NeuMF.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuMF HR: 0.7705, NeuMF NDCG: 0.3941, \n",
      " MLP HR: 0.7705, MLP NDCG: 0.3986 \n",
      " GMF HR: 0.7508, GMF NDCG: 0.3722\n"
     ]
    }
   ],
   "source": [
    "nmf = NeuMF(GMF = gmf, MLP = mlp, num_factor = num_factor).to(device)\n",
    "nmf.load_state_dict(torch.load(weight_dir + f'NeuMF.pt'))\n",
    "\n",
    "gmf = GMF(num_user = num_user, num_item = num_item, num_factor = num_factor).to(device)\n",
    "gmf.load_state_dict(torch.load(weight_dir + f'GMF.pt'))\n",
    "\n",
    "mlp = MLP(num_user = num_user, num_item = num_item, num_factor = num_factor, num_layers = num_layers, dropout = dropout).to(device)\n",
    "mlp.load_state_dict(torch.load(weight_dir + f'MLP.pt'))\n",
    "\n",
    "gmf_hr, gmf_ndcg = metrics(model = gmf, test_loader = test_loader, top_k = top_k)\n",
    "mlp_hr, mlp_ndcg  = metrics(model = mlp, test_loader = test_loader, top_k = top_k)\n",
    "nmf_hr, nmf_ndcg = metrics(model = nmf, test_loader = test_loader, top_k = top_k)\n",
    "\n",
    "print(f\"NeuMF HR: {nmf_hr:.4f}, NeuMF NDCG: {nmf_ndcg:.4f}, \\n MLP HR: {mlp_hr:.4f}, MLP NDCG: {mlp_ndcg:.4f} \\n GMF HR: {gmf_hr:.4f}, GMF NDCG: {gmf_ndcg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
